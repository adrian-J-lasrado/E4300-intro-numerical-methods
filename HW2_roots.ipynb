{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "header1",
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "header2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, restart the kernel (in the menubar, select Kernel $\\rightarrow$ Restart) and then run all cells (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says YOUR CODE HERE or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "header3",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# HW 2:  Root Finding and Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Question 1 - Finding the Root\n",
    "\n",
    "Let's say that we wanted to calculate $\\sqrt{M}$ given that $M \\in \\mathbb{R}$ and $M > 0$ and that we did not want to use the function `sqrt` directly.  One way to do this is to solve for the zeros of the function $f(x) = x^2 - M$.\n",
    "\n",
    " - Note that not all the methods will work!\n",
    " - Make sure to handle the case where $M_0 = \\sqrt{M}$.\n",
    " - We are only looking for the positive root of $f(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q1-a",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**(a)** (5 points) Write a function that uses fixed-point iteration to solve for the zeros of $f(x)$.  \n",
    "\n",
    "Note: There are multiple ways to write the iteration function $g(x)$, some work better than others.  Make sure to use the input function $f(x)$ to formulate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "A1-a",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def fixed_point(x_0, f, tolerance):\n",
    "    \"\"\"Find the zeros of the given function f using fixed-point iteration\n",
    "    \n",
    "    :Input:\n",
    "     - *x_0* (float) - Initial iterate\n",
    "     - *f* (function) - The function that will be analyzed\n",
    "     - *tolerance* (float) - Stopping tolerance for iteration\n",
    "     \n",
    "    :Output:\n",
    "    If the iteration was successful the return values are:\n",
    "     - *M* (float) - Zero found via the given intial iterate.\n",
    "     - *n* (int) - Number of iterations it took to achieve the specified\n",
    "       tolerance.\n",
    "    otherwise\n",
    "     - *x* (float) - Last iterate found\n",
    "     - *n* (int) - *n = -1*\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parameters\n",
    "    MAX_STEPS = 1000\n",
    "    \n",
    "    # INSERT CODE HERE\n",
    "    raise NotImplementedError(\"Replace this statement with your solution.\")\n",
    "    \n",
    "    return x, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "T1-a",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "M = 1.8\n",
    "TOLERANCE = 1e-10\n",
    "f = lambda x: x**2 - M\n",
    "\n",
    "# Note that this test probably will fail\n",
    "try:\n",
    "    M_f, n = fixed_point(2.0, f, TOLERANCE)\n",
    "except OverflowError:\n",
    "    print \"Fixed-point test failed!\"\n",
    "    print \"Success!\"\n",
    "else:\n",
    "    if n == -1:\n",
    "        print \"Fixed-point test failed!\"\n",
    "        print \"Success!\"\n",
    "    else:\n",
    "        print M_f, n\n",
    "        raise ValueError(\"Test should have failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q1-b",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**(b)** (5 points) Write a function that uses Newton's method to find the roots of $f(x)$. The analytical derivative of $f'(x)$ is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "A1-b",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def newton(x_0, f, f_prime, tolerance):\n",
    "    \"\"\"Find the zeros of the given function f using Newton's method\n",
    "    \n",
    "    :Input:\n",
    "     - *M_0* (float) - Initial iterate\n",
    "     - *f* (function) - The function that will be analyzed\n",
    "     - *f_prime* (function) - The derivative of *f*\n",
    "     - *tolerance* (float) - Stopping tolerance for iteration\n",
    "     \n",
    "    :Output:\n",
    "    If the iteration was successful the return values are:\n",
    "     - *M* (float) - Zero found via the given intial iterate.\n",
    "     - *n* (int) - Number of iterations it took to achieve the specified\n",
    "       tolerance.\n",
    "    otherwise\n",
    "     - *M* (float) - Last iterate found\n",
    "     - *n* (int) - *n = -1*\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parameters\n",
    "    MAX_STEPS = 1000\n",
    "    \n",
    "    # INSERT CODE HERE\n",
    "    raise NotImplementedError(\"Replace this statement with your solution.\")\n",
    "    \n",
    "    return x, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "T-1b",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "M = 3.0\n",
    "TOLERANCE = 1e-10\n",
    "f = lambda x: x**2 - M\n",
    "f_prime = lambda x: 2.0 * x\n",
    "\n",
    "M_f, n = newton(2.0, f, f_prime, TOLERANCE)\n",
    "numpy.testing.assert_almost_equal(M_f, numpy.sqrt(M))\n",
    "print M_f, n\n",
    "assert(n == 4)\n",
    "\n",
    "M_f, n = newton(numpy.sqrt(M), f, f_prime, TOLERANCE)\n",
    "print M_f, n\n",
    "assert(n == 0)\n",
    "\n",
    "print \"Success!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q1-c",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**(c)** (5 points) Write a function to find the zeros of $f(x)$ using the secant method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "A1-c",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def secant(x_0, f, tolerance):\n",
    "    \"\"\"Find the zeros of the given function f using the secant method\n",
    "    \n",
    "    :Input:\n",
    "     - *M_0* (float) - Initial bracket\n",
    "     - *f* (function) - The function that will be analyzed\n",
    "     - *tolerance* (float) - Stopping tolerance for iteration\n",
    "     \n",
    "    :Output:\n",
    "    If the iteration was successful the return values are:\n",
    "     - *M* (float) - Zero found via the given intial iterate.\n",
    "     - *n* (int) - Number of iterations it took to achieve the specified\n",
    "       tolerance.\n",
    "    otherwise\n",
    "     - *M* (float) - Last iterate found\n",
    "     - *n* (int) - *n = -1*\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parameters\n",
    "    MAX_STEPS = 1000\n",
    "    \n",
    "    # INSERT CODE HERE\n",
    "    raise NotImplementedError(\"Replace this statement with your solution.\")\n",
    "    \n",
    "    return x, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "T1-c",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "M = 3.0\n",
    "TOLERANCE = 1e-10\n",
    "f = lambda x: x**2 - M\n",
    "\n",
    "M_f, n = secant([0.0, 3.0], f, TOLERANCE)\n",
    "numpy.testing.assert_almost_equal(M_f, numpy.sqrt(M))\n",
    "print M_f, n\n",
    "assert(n == 7)\n",
    "\n",
    "M_f, n = secant([1.0, numpy.sqrt(M)], f, TOLERANCE)\n",
    "assert(n == 0)\n",
    "\n",
    "print \"Success!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q1-d",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**(d)** (5 points) Using the theory and illustrative plots why the fixed-point method did not work (pick a bracket that demonstrates the problem well).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "A1-d1",
     "locked": false,
     "points": 2,
     "solution": true
    }
   },
   "source": [
    "The range is not contained within the domain and therefore fixed-point iteration will not converge.  The plot below should be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "A1-d2",
     "locked": false,
     "points": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Question 2 - Bessel Function Zeros\n",
    "\n",
    "The zeros of the Bessel functions $J_0(x)$ can be important for a number of applications.  Considering only $x \\geq 0$ \n",
    "we are going to find the first ten zeros of $J_0(x)$ by using a hybrid approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q2-a",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**(a)** (5 points) Plot the Bessel function $J_0(x)$ and its zeros on the same plot.  Note that the module `scipy.special` contains functions dealing with the Bessel functions (`jn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "A2-a",
     "locked": false,
     "points": 5,
     "solution": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q2-b",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**(b)** (15 points) Now write a function `j0_zeros` that takes two tolerances, a bracket size tolerance `bracket_tolerance` and `tolerance` for the final convergence tolerance.  Given an initial bracket, the function should perform secant iterations until the bracket size is less than `bracket_tolerance`.  If this is successful then proceed with Newton's method using the newest value of the bracket until `tolerance` is reached.  Return both the zero found and the number of steps needed in each iteration.  Also write a `doc-string` for the function.\n",
    "\n",
    "Notes:\n",
    " - Newton's method by itself does not work here given the initial brackets provided.\n",
    " - The secant method does work however it is slower than the approach outlined.\n",
    " - Try playing a bit yourself with the tolerances used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "A2-b",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import scipy.special\n",
    "\n",
    "# Note that the num_steps being returned should be a list \n",
    "# of the number of steps being used in each method\n",
    "def j0_zeros(x0, bracket_tolerance, tolerance):\n",
    "    \n",
    "    # INSERT CODE HERE\n",
    "    raise NotImplementedError(\"Replace this statement with your solution.\")\n",
    "    \n",
    "    return x, num_steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "T2-b",
     "locked": true,
     "points": 15,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "brackets = [[ 2.0,  3.0], [ 4.0,  7.0], [ 7.0, 10.0], [10.0, 12.0], \n",
    "            [13.0, 15.0], [17.0, 19.0], [19.0, 22.0], \n",
    "            [22.0, 26.0], [26.0, 29.0], [29.0, 32.0]]\n",
    "\n",
    "zero = []\n",
    "for bracket in brackets:\n",
    "    x, num_steps = j0_zeros(bracket, 1e-1, 1e-15)\n",
    "    print x, num_steps\n",
    "    zero.append(x)\n",
    "numpy.testing.assert_allclose(zero, scipy.special.jn_zeros(0, 10), rtol=1e-14)\n",
    "print \"Success!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q3",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Question 3 - Newton's Method Convergence\n",
    "\n",
    "Recall that Newton's method converges as\n",
    "\n",
    "$$|\\epsilon_{n+1}| = \\frac{|f''(c)|}{2 |f'(x_n)|} |\\epsilon_n|^2$$\n",
    "\n",
    "with $\\epsilon_n = x_n - x^*$ where $x^*$ is the true solution and $c$ is between $x_n$ and $x^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q3-a",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**(a)** (10 points) Show that the Newton iteration when $f(x) = x^2 - M$ with $M > 0$ is\n",
    "\n",
    "$$x_{n+1} = \\frac{1}{2} \\left (x_n + \\frac{M}{x_n} \\right )$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "A3-a",
     "locked": false,
     "points": 10,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "Q3-b",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**(b)** (10 points) From this update scheme show that \n",
    "\n",
    "$$\\frac{x_{n+1} - \\sqrt{M}}{(x_n - \\sqrt{M})^2} = \\frac{1}{2 x_n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "A3-b",
     "locked": false,
     "points": 10,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q3-c",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**(c)** (10 points) Confirm that the asymptotic error convergence matches the general convergence for Newton's method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "A3-c",
     "locked": false,
     "points": 10,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q4",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Question 4 - Optimization of a Data Series\n",
    "\n",
    "For the following questions we are given a set of data $(t_0, y_0), (t_1, y_1), \\ldots, (t_N, y_N)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q4-a",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**(a)** (15 points) Write a function that takes in the data series $(t_i, y_i)$ and finds the value at a point $t_\\ast$ by constructing the equation of the line between the two data points that bound $t_\\ast$ and evaluating the resulting function at $t_\\ast$.  Write a `doc-string` for the function.\n",
    "\n",
    "Hints:\n",
    " - Make sure to handle the case that $t_\\ast = t_i$.\n",
    " - If $t_\\ast < t_0$ or $t_\\ast > t_N$ then return the corresponding value $y_0$ or $y_N$.\n",
    " - If you write your function so that $t_\\ast$ can be an array you can use the plotting code in the cell.  Otherwise just delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "A4-a",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def linear_eval(t, y, t_star):\n",
    "    \n",
    "    # INSERT CODE HERE\n",
    "    raise NotImplementedError(\"Replace this statement with your solution.\")\n",
    "            \n",
    "    return y_star\n",
    "\n",
    "N = 10\n",
    "t_fine = numpy.linspace(-numpy.pi, numpy.pi, 100)\n",
    "t_rand = numpy.random.rand(N + 1) * (2.0 * numpy.pi) - numpy.pi\n",
    "t_rand.sort()\n",
    "f = lambda x: numpy.sin(x) * numpy.cos(x)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figwidth(fig.get_figwidth()*1.5)\n",
    "axes = fig.add_subplot(1, 1, 1)\n",
    "axes.plot(t_fine, f(t_fine), 'k-', label=\"True\")\n",
    "axes.plot(t_rand, f(t_rand), 'og', label=\"Sample Data\")\n",
    "axes.plot(t_fine, linear_eval(t_rand, f(t_rand), t_fine), 'xb', label=\"linear_eval\")\n",
    "axes.set_xlim((-numpy.pi, numpy.pi))\n",
    "axes.set_title(\"Demo Plot\")\n",
    "axes.set_xlabel('$t$')\n",
    "axes.set_ylabel('$f(t)$')\n",
    "axes.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "T4-a",
     "locked": true,
     "points": 15,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "f = lambda x: numpy.sin(x) * numpy.cos(x)\n",
    "t = numpy.linspace(-1, 1, N + 1)\n",
    "t_star = 0.5\n",
    "\n",
    "numpy.testing.assert_almost_equal(linear_eval(t, f(t), t_star), f(t_star), verbose=True, decimal=2)\n",
    "print \"Success!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q4-b",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**(b)** (10 points) Using the function you wrote in part (a) write a function that uses Golden search to find the minimum of a series of data.  Again you can use the plotting code available if your `linear_eval` function from part (a) handles arrays.  Write a `doc-string` for the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "A4-b",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def golden_search(bracket, t, y, max_steps=100, tolerance=1e-4):\n",
    "\n",
    "    phi = (numpy.sqrt(5.0) - 1.0) / 2.0\n",
    "    \n",
    "    # INSERT CODE HERE\n",
    "    raise NotImplementedError(\"Replace this statement with your solution.\")  \n",
    "    \n",
    "    return t_star\n",
    "\n",
    "N = 50\n",
    "t = numpy.random.rand(N + 1) * (2.0 * numpy.pi) - numpy.pi\n",
    "t.sort()\n",
    "y = numpy.sin(t) * numpy.cos(t)\n",
    "t_star = golden_search([0.1, 3.0 * numpy.pi / 4.0], t, y)\n",
    "t_true = numpy.pi / 4.0\n",
    "\n",
    "fig = plt.figure()\n",
    "axes = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "axes.plot(t, y, 'x', label=\"data\")\n",
    "t_fine = numpy.linspace(-numpy.pi, numpy.pi, 100)\n",
    "axes.plot(t_fine, numpy.sin(t_fine) * numpy.cos(t_fine), 'k', label=\"$f(x)$\")\n",
    "axes.plot(t_star, linear_eval(t, y, t_star), 'go')\n",
    "axes.plot(t_true, numpy.sin(t_true) * numpy.cos(t_true), 'ko', label=\"True\")\n",
    "axes.set_xlim((0.0, numpy.pi / 2.0))\n",
    "axes.set_ylim((0.0, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "T4-b",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "t = numpy.random.rand(N + 1) * (2.0 * numpy.pi) - numpy.pi\n",
    "t.sort()\n",
    "y = numpy.sin(t) * numpy.cos(t)\n",
    "t_star = golden_search([0.1, 3.0 * numpy.pi / 4.0], t, y)\n",
    "t_true = numpy.pi / 4.0\n",
    "abs_error = numpy.abs(t_star - t_true)\n",
    "rel_error = numpy.abs(t_star - t_true) / numpy.abs(t_true)\n",
    "print \"Error: %s, %s\" % (abs_error, rel_error)\n",
    "numpy.testing.assert_allclose(abs_error, 0.0, rtol=1e-1, atol=1e-1)\n",
    "print \"Success!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "Q4-c",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**(c)** (5 points) Below is sample code that plots the number of sample points $N$ vs. the relative error.  Note because we are sampling at random points that we do each $N$ 6 times and average the relative error to reduce noise.  Additionally a line is drawn representing what would be linear (1st order) convergence.\n",
    "\n",
    "Modify this code and try it out on other problems.  Do you continue to see linear convergence?  What about if you change how we sample points?  Make sure that you change your initial interval and range of values of $t$ inside the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "A4-c",
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "f = lambda t: numpy.sin(t) * numpy.cos(t)\n",
    "N_range = numpy.array([2**n for n in range(4, 10)], dtype=int)\n",
    "rel_error = numpy.zeros(len(N_range))\n",
    "t_true = numpy.pi / 4.0\n",
    "\n",
    "for (i, N) in enumerate(N_range):\n",
    "    for j in xrange(6):\n",
    "        t = numpy.random.rand(N + 1) * (2.0 * numpy.pi) - numpy.pi\n",
    "        t.sort()\n",
    "        y = f(t)\n",
    "        t_star = golden_search([0.1, 3.0 * numpy.pi / 4.0], t, y)\n",
    "        rel_error[i] += numpy.abs(t_star - t_true) / numpy.abs(t_true)\n",
    "    rel_error[i] /= 6\n",
    "\n",
    "order_C = lambda N, error, order: numpy.exp(numpy.log(error) - order * numpy.log(N))\n",
    "    \n",
    "fig = plt.figure()\n",
    "axes = fig.add_subplot(1, 1, 1)\n",
    "axes.loglog(N_range, rel_error, 'ko', label=\"Ave. Error\")\n",
    "axes.loglog(N_range, order_C(N_range[0], rel_error[0], -1.0) * N_range**(-1.0), 'r', label=\"1st order\")\n",
    "axes.loglog(N_range, order_C(N_range[0], rel_error[0], -2.0) * N_range**(-2.0), 'b', label=\"1st Order\")\n",
    "axes.set_xlabel(\"N\")\n",
    "axes.set_ylabel(\"Relative Error\")\n",
    "axes.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "A4-c",
     "locked": false,
     "points": 5,
     "solution": true
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
